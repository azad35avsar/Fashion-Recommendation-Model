{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading in the csv data\ndf = pd.read_csv('/kaggle/input/fashion-product-images-small/myntradataset/styles.csv',error_bad_lines=False)\n\ndf.head()","execution_count":3,"outputs":[{"output_type":"stream","text":"b'Skipping line 6044: expected 10 fields, saw 11\\nSkipping line 6569: expected 10 fields, saw 11\\nSkipping line 7399: expected 10 fields, saw 11\\nSkipping line 7939: expected 10 fields, saw 11\\nSkipping line 9026: expected 10 fields, saw 11\\nSkipping line 10264: expected 10 fields, saw 11\\nSkipping line 10427: expected 10 fields, saw 11\\nSkipping line 10905: expected 10 fields, saw 11\\nSkipping line 11373: expected 10 fields, saw 11\\nSkipping line 11945: expected 10 fields, saw 11\\nSkipping line 14112: expected 10 fields, saw 11\\nSkipping line 14532: expected 10 fields, saw 11\\nSkipping line 15076: expected 10 fields, saw 12\\nSkipping line 29906: expected 10 fields, saw 11\\nSkipping line 31625: expected 10 fields, saw 11\\nSkipping line 33020: expected 10 fields, saw 11\\nSkipping line 35748: expected 10 fields, saw 11\\nSkipping line 35962: expected 10 fields, saw 11\\nSkipping line 37770: expected 10 fields, saw 11\\nSkipping line 38105: expected 10 fields, saw 11\\nSkipping line 38275: expected 10 fields, saw 11\\nSkipping line 38404: expected 10 fields, saw 12\\n'\n","name":"stderr"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"      id gender masterCategory subCategory  articleType baseColour  season  \\\n0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n\n     year   usage                             productDisplayName  \n0  2011.0  Casual               Turtle Check Men Navy Blue Shirt  \n1  2012.0  Casual             Peter England Men Party Blue Jeans  \n2  2016.0  Casual                       Titan Women Silver Watch  \n3  2011.0  Casual  Manchester United Men Solid Black Track Pants  \n4  2012.0  Casual                          Puma Men Grey T-shirt  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gender</th>\n      <th>masterCategory</th>\n      <th>subCategory</th>\n      <th>articleType</th>\n      <th>baseColour</th>\n      <th>season</th>\n      <th>year</th>\n      <th>usage</th>\n      <th>productDisplayName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15970</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Topwear</td>\n      <td>Shirts</td>\n      <td>Navy Blue</td>\n      <td>Fall</td>\n      <td>2011.0</td>\n      <td>Casual</td>\n      <td>Turtle Check Men Navy Blue Shirt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39386</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Bottomwear</td>\n      <td>Jeans</td>\n      <td>Blue</td>\n      <td>Summer</td>\n      <td>2012.0</td>\n      <td>Casual</td>\n      <td>Peter England Men Party Blue Jeans</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>59263</td>\n      <td>Women</td>\n      <td>Accessories</td>\n      <td>Watches</td>\n      <td>Watches</td>\n      <td>Silver</td>\n      <td>Winter</td>\n      <td>2016.0</td>\n      <td>Casual</td>\n      <td>Titan Women Silver Watch</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21379</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Bottomwear</td>\n      <td>Track Pants</td>\n      <td>Black</td>\n      <td>Fall</td>\n      <td>2011.0</td>\n      <td>Casual</td>\n      <td>Manchester United Men Solid Black Track Pants</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>53759</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Topwear</td>\n      <td>Tshirts</td>\n      <td>Grey</td>\n      <td>Summer</td>\n      <td>2012.0</td>\n      <td>Casual</td>\n      <td>Puma Men Grey T-shirt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()\ndf.nunique()\ndf.columns","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"Index(['id', 'gender', 'masterCategory', 'subCategory', 'articleType',\n       'baseColour', 'season', 'year', 'usage', 'productDisplayName'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at all the unique labels in all categorical columns \ncat_columns = ['gender', 'masterCategory', 'subCategory', 'articleType','baseColour', 'season', 'year', 'usage']\n\nfor col in cat_columns:\n    print(col)\n    print(df[col].unique())\n    print('-------------------------')","execution_count":5,"outputs":[{"output_type":"stream","text":"gender\n['Men' 'Women' 'Boys' 'Girls' 'Unisex']\n-------------------------\nmasterCategory\n['Apparel' 'Accessories' 'Footwear' 'Personal Care' 'Free Items'\n 'Sporting Goods' 'Home']\n-------------------------\nsubCategory\n['Topwear' 'Bottomwear' 'Watches' 'Socks' 'Shoes' 'Belts' 'Flip Flops'\n 'Bags' 'Innerwear' 'Sandal' 'Shoe Accessories' 'Fragrance' 'Jewellery'\n 'Lips' 'Saree' 'Eyewear' 'Scarves' 'Dress' 'Loungewear and Nightwear'\n 'Wallets' 'Apparel Set' 'Headwear' 'Mufflers' 'Skin Care' 'Makeup'\n 'Free Gifts' 'Ties' 'Accessories' 'Nails' 'Beauty Accessories'\n 'Water Bottle' 'Skin' 'Eyes' 'Bath and Body' 'Gloves'\n 'Sports Accessories' 'Cufflinks' 'Sports Equipment' 'Stoles' 'Hair'\n 'Perfumes' 'Home Furnishing' 'Umbrellas' 'Wristbands' 'Vouchers']\n-------------------------\narticleType\n['Shirts' 'Jeans' 'Watches' 'Track Pants' 'Tshirts' 'Socks' 'Casual Shoes'\n 'Belts' 'Flip Flops' 'Handbags' 'Tops' 'Bra' 'Sandals' 'Shoe Accessories'\n 'Sweatshirts' 'Deodorant' 'Formal Shoes' 'Bracelet' 'Lipstick' 'Flats'\n 'Kurtas' 'Waistcoat' 'Sports Shoes' 'Shorts' 'Briefs' 'Sarees'\n 'Perfume and Body Mist' 'Heels' 'Sunglasses' 'Innerwear Vests' 'Pendant'\n 'Laptop Bag' 'Scarves' 'Dresses' 'Night suits' 'Skirts' 'Wallets'\n 'Blazers' 'Ring' 'Kurta Sets' 'Clutches' 'Shrug' 'Backpacks' 'Caps'\n 'Trousers' 'Earrings' 'Camisoles' 'Boxers' 'Jewellery Set' 'Dupatta'\n 'Capris' 'Lip Gloss' 'Bath Robe' 'Mufflers' 'Tunics' 'Jackets' 'Trunk'\n 'Lounge Pants' 'Face Wash and Cleanser' 'Necklace and Chains'\n 'Duffel Bag' 'Sports Sandals' 'Foundation and Primer' 'Sweaters'\n 'Free Gifts' 'Trolley Bag' 'Tracksuits' 'Swimwear' 'Shoe Laces'\n 'Fragrance Gift Set' 'Bangle' 'Nightdress' 'Ties' 'Baby Dolls' 'Leggings'\n 'Highlighter and Blush' 'Travel Accessory' 'Kurtis' 'Mobile Pouch'\n 'Messenger Bag' 'Lip Care' 'Nail Polish' 'Eye Cream' 'Accessory Gift Set'\n 'Beauty Accessory' 'Jumpsuit' 'Kajal and Eyeliner' 'Water Bottle'\n 'Suspenders' 'Face Moisturisers' 'Lip Liner' 'Robe' 'Salwar and Dupatta'\n 'Patiala' 'Stockings' 'Eyeshadow' 'Headband' 'Tights' 'Nail Essentials'\n 'Churidar' 'Lounge Tshirts' 'Face Scrub and Exfoliator' 'Lounge Shorts'\n 'Gloves' 'Wristbands' 'Tablet Sleeve' 'Ties and Cufflinks' 'Footballs'\n 'Compact' 'Stoles' 'Shapewear' 'Nehru Jackets' 'Salwar' 'Cufflinks'\n 'Jeggings' 'Hair Colour' 'Concealer' 'Rompers' 'Sunscreen' 'Booties'\n 'Mask and Peel' 'Waist Pouch' 'Hair Accessory' 'Body Lotion' 'Rucksacks'\n 'Basketballs' 'Lehenga Choli' 'Clothing Set' 'Mascara' 'Cushion Covers'\n 'Key chain' 'Rain Jacket' 'Toner' 'Lip Plumper' 'Umbrellas'\n 'Face Serum and Gel' 'Hat' 'Mens Grooming Kit' 'Makeup Remover'\n 'Body Wash and Scrub' 'Suits' 'Ipad']\n-------------------------\nbaseColour\n['Navy Blue' 'Blue' 'Silver' 'Black' 'Grey' 'Green' 'Purple' 'White'\n 'Beige' 'Brown' 'Bronze' 'Teal' 'Copper' 'Pink' 'Off White' 'Maroon'\n 'Red' 'Khaki' 'Orange' 'Yellow' 'Charcoal' 'Gold' 'Steel' 'Tan' 'Multi'\n 'Magenta' 'Lavender' 'Sea Green' 'Cream' 'Peach' 'Olive' 'Skin'\n 'Burgundy' 'Coffee Brown' 'Grey Melange' 'Rust' 'Rose' 'Lime Green'\n 'Mauve' 'Turquoise Blue' 'Metallic' 'Mustard' 'Taupe' 'Nude'\n 'Mushroom Brown' 'Fluorescent Green']\n-------------------------\nseason\n['Fall' 'Summer' 'Winter' 'Spring']\n-------------------------\nyear\n[2011. 2012. 2016. 2017. 2015. 2014. 2010. 2013. 2018. 2019. 2007. 2009.\n 2008.]\n-------------------------\nusage\n['Casual' 'Ethnic' 'Formal' 'Sports' 'Smart Casual' 'Travel' 'Party'\n 'Home']\n-------------------------\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The images in this Dataset are very low resolution (80x60). We will be using the categories that are visually distinct even at such a low resolution.\n\nThe categories year, usage, season, and gender mighht not be clearly visually distinct in some cases, so we wont be using them.\n\nThe categories, masterCategory and subCategory are distinct enough groups, but they are not specific enough for practical use. \n\nThe categories we will use are articleType and baseColour(You can use more categories if you want).\n\nThere are many unique labels in these categories, we will only be using the ones with more than 1000 examples, since we would need a good number of samples for proper classifcation."},{"metadata":{"trusted":true},"cell_type":"code","source":"value_counts = df['articleType'].value_counts()\n\nindexes = value_counts.index\n\nvalues = value_counts.values\n\nfor i in range(len(value_counts)):\n\n    if values[i] <1000:\n        break\n\ntypes_used = indexes[:i]\nprint('Article types used: ',types_used)","execution_count":6,"outputs":[{"output_type":"stream","text":"Article types used:  Index(['Tshirts', 'Shirts', 'Casual Shoes', 'Watches', 'Sports Shoes',\n       'Kurtas', 'Tops', 'Handbags', 'Heels', 'Sunglasses'],\n      dtype='object')\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"value_counts = df['baseColour'].value_counts()\n\nindexes = value_counts.index\n\nvalues = value_counts.values\n\nfor i in range(len(value_counts)):\n\n    if values[i] <1000:\n        break\n\ncolours_used = indexes[:i]\nprint('Base Colours used: ',colours_used)","execution_count":7,"outputs":[{"output_type":"stream","text":"Base Colours used:  Index(['Black', 'White', 'Blue', 'Brown', 'Grey', 'Red', 'Green', 'Pink',\n       'Navy Blue', 'Purple', 'Silver'],\n      dtype='object')\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing all the examples with labels other than the selected ones\n \ndf = df[df['articleType'].isin(types_used)]\ndf = df[df['baseColour'].isin(colours_used)]","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#number of examples we are left with\nlen(df)","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"21835"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now we will load in all the images from the remaining rows, and convert them to numpy arrays with img_to_array function in keras."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []\n\n# Reading all the images and processing the data in them \n\nfrom tensorflow.keras.preprocessing.image import img_to_array\nimport cv2\n\nIX = 80\nIY = 60\n\ninvalid_ids = []\n\nfor name in df.id:\n\n    try:\n        image = cv2.imread('/kaggle/input/fashion-product-images-small/myntradataset/images/'+str(name)+'.jpg')\n        image = cv2.resize(image, (IX,IY) )\n        image = img_to_array(image)\n        data.append(image)        \n    except: \n        # Images for certain ids are missing, so they are not added to the dataset  \n        invalid_ids.append(name)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ids of missing images\nprint('invalid ids:')\nprint(invalid_ids)","execution_count":15,"outputs":[{"output_type":"stream","text":"invalid ids:\n[39403, 39425]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = []\n\nused_columns = ['subCategory','baseColour']\n\n# getting labels for the columns used\n\nfor index, row in df.iterrows():\n\n    if row['id'] in invalid_ids:\n        continue\n\n    tags = []\n\n    for col in used_columns:\n        tags.append(row[col])\n\n    labels.append(tags)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n# converting data into numpy arrays\n\ndata = np.array(data, dtype=\"float\") / 255.0\nlabels = np.array(labels)\n\nprint(labels)","execution_count":17,"outputs":[{"output_type":"stream","text":"[['Topwear' 'Navy Blue']\n ['Watches' 'Silver']\n ['Topwear' 'Grey']\n ...\n ['Shoes' 'White']\n ['Topwear' 'Blue']\n ['Watches' 'Pink']]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Now we will create binary vectors as the outputs of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\n\n# creating a binary vector for the input labels \n\nmlb = MultiLabelBinarizer()\nlabels = mlb.fit_transform(labels)\n\nprint(mlb.classes_)\nprint(labels[0])","execution_count":18,"outputs":[{"output_type":"stream","text":"['Bags' 'Belts' 'Black' 'Blue' 'Brown' 'Eyewear' 'Free Gifts' 'Green'\n 'Grey' 'Navy Blue' 'Pink' 'Purple' 'Red' 'Shoes' 'Silver' 'Topwear'\n 'Watches' 'White']\n[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n\ninputShape = (IY, IX, 3)\n\n# A very simple sequential model is used since the images are very low resolution and the categories are fiarly distinct\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten()) \n\nmodel.add(Dense(128))\nmodel.add(Activation('sigmoid'))\n\n\nout = len(mlb.classes_)\n\nmodel.add(Dense(out))\nmodel.add(Activation('sigmoid')) # activation function for the final layer has to be sigmoid, since mutiple output labels can have value 1\n                    \nmodel.compile(loss='binary_crossentropy', # loss function has to be binary_crossentropy, it is calculated seperately for each of the outputs\n              optimizer='adam',\n              metrics=['mse'])","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# splitting data into testing and training set \n\n(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.1, random_state=42)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = 32\nE = 50\n\n#training the model \nmodel.fit(x=trainX,y=trainY,\n          epochs=E ,verbose=1)","execution_count":21,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n615/615 [==============================] - 6s 5ms/step - loss: 0.2811 - mse: 0.0814\nEpoch 2/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.1118 - mse: 0.0308\nEpoch 3/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0897 - mse: 0.0248\nEpoch 4/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0813 - mse: 0.0226\nEpoch 5/50\n615/615 [==============================] - 3s 6ms/step - loss: 0.0759 - mse: 0.0211\nEpoch 6/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0709 - mse: 0.0199\nEpoch 7/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0706 - mse: 0.0199\nEpoch 8/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0643 - mse: 0.0181\nEpoch 9/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0628 - mse: 0.0177\nEpoch 10/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0600 - mse: 0.0169\nEpoch 11/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0568 - mse: 0.0159\nEpoch 12/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0538 - mse: 0.0151\nEpoch 13/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0508 - mse: 0.0143\nEpoch 14/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0525 - mse: 0.0147\nEpoch 15/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0475 - mse: 0.0133\nEpoch 16/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0457 - mse: 0.0127\nEpoch 17/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0466 - mse: 0.0131\nEpoch 18/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0431 - mse: 0.0120\nEpoch 19/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0402 - mse: 0.0112\nEpoch 20/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0405 - mse: 0.0113\nEpoch 21/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0372 - mse: 0.0103\nEpoch 22/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0350 - mse: 0.0096\nEpoch 23/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0338 - mse: 0.0093\nEpoch 24/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0352 - mse: 0.0097\nEpoch 25/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0323 - mse: 0.0089\nEpoch 26/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0299 - mse: 0.0081\nEpoch 27/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0284 - mse: 0.0077\nEpoch 28/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0276 - mse: 0.0075\nEpoch 29/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0260 - mse: 0.0070\nEpoch 30/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0256 - mse: 0.0069\nEpoch 31/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0240 - mse: 0.0064\nEpoch 32/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0228 - mse: 0.0060\nEpoch 33/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0224 - mse: 0.0059\nEpoch 34/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0219 - mse: 0.0058\nEpoch 35/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0207 - mse: 0.0054\nEpoch 36/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0218 - mse: 0.0058\nEpoch 37/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0196 - mse: 0.0051\nEpoch 38/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0189 - mse: 0.0049\nEpoch 39/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0178 - mse: 0.0047\nEpoch 40/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0173 - mse: 0.0045\nEpoch 41/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0170 - mse: 0.0044\nEpoch 42/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0168 - mse: 0.0043\nEpoch 43/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0164 - mse: 0.0043\nEpoch 44/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0154 - mse: 0.0039\nEpoch 45/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0161 - mse: 0.0042\nEpoch 46/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0172 - mse: 0.0045\nEpoch 47/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0157 - mse: 0.0041\nEpoch 48/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0129 - mse: 0.0032\nEpoch 49/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0132 - mse: 0.0034\nEpoch 50/50\n615/615 [==============================] - 3s 5ms/step - loss: 0.0131 - mse: 0.0034\n","name":"stdout"},{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f4b00130b10>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(testX)\n\n\n# since the predictions of the model are sigmoid, we will first binarize them to 0 or 1\npred_binarized = []\n\nfor pred in preds:\n    vals = []\n    for val in pred:\n        if val > 0.5:\n            vals.append(1)\n        else:\n            vals.append(0)\n    pred_binarized.append(vals) \n\npred_binarized = np.array(pred_binarized)   \n\n\n# we convert the output vectors to the predicted labels\ntrue_test_labels = mlb.inverse_transform(testY)\npred_test_labels = mlb.inverse_transform(pred_binarized)\n\ncorrect = 0\nwrong = 0\n\n# Evaluating the predictions of the model\n\nfor i in range(len(testY)):\n\n    true_labels = list(true_test_labels[i])\n\n    pred_labels = list(pred_test_labels[i])\n\n    label1 = true_labels[0]\n    label2 = true_labels[1]\n\n    if label1 in pred_labels:\n        correct+=1\n    else:\n        wrong+=1\n\n    if label2 in pred_labels:\n        correct+=1\n    else:\n        wrong+=1    \n\n\n\nprint('correct: ', correct)\nprint('missing/wrong: ', wrong)\nprint('Accuracy: ',correct/(correct+wrong))","execution_count":22,"outputs":[{"output_type":"stream","text":"correct:  3696\nmissing/wrong:  672\nAccuracy:  0.8461538461538461\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We can see that this model identifies 84.61% of the labels correctly, let us see what that looks like in practice"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(20):\n    print('True labels: ',true_test_labels[i],' Predicted labels: ',pred_test_labels[i])","execution_count":23,"outputs":[{"output_type":"stream","text":"True labels:  ('Topwear', 'White')  Predicted labels:  ('Topwear', 'White')\nTrue labels:  ('Black', 'Shoes')  Predicted labels:  ('Blue', 'Shoes')\nTrue labels:  ('Green', 'Topwear')  Predicted labels:  ('Green', 'Topwear')\nTrue labels:  ('Purple', 'Topwear')  Predicted labels:  ('Pink', 'Topwear')\nTrue labels:  ('Green', 'Topwear')  Predicted labels:  ('Green', 'Topwear')\nTrue labels:  ('Shoes', 'White')  Predicted labels:  ('Shoes', 'White')\nTrue labels:  ('Brown', 'Shoes')  Predicted labels:  ('Brown', 'Shoes')\nTrue labels:  ('Black', 'Watches')  Predicted labels:  ('Black', 'Watches')\nTrue labels:  ('Black', 'Watches')  Predicted labels:  ('Black', 'Watches')\nTrue labels:  ('Red', 'Topwear')  Predicted labels:  ('Brown', 'Topwear')\nTrue labels:  ('Brown', 'Shoes')  Predicted labels:  ('Brown', 'Shoes')\nTrue labels:  ('Black', 'Shoes')  Predicted labels:  ('Black', 'Shoes')\nTrue labels:  ('Bags', 'Brown')  Predicted labels:  ('Bags', 'Brown')\nTrue labels:  ('Shoes', 'White')  Predicted labels:  ('Shoes', 'White')\nTrue labels:  ('Black', 'Topwear')  Predicted labels:  ('Black', 'Topwear')\nTrue labels:  ('Black', 'Shoes')  Predicted labels:  ('Black', 'Shoes')\nTrue labels:  ('Red', 'Topwear')  Predicted labels:  ('Red', 'Topwear')\nTrue labels:  ('Shoes', 'White')  Predicted labels:  ('Shoes',)\nTrue labels:  ('Blue', 'Topwear')  Predicted labels:  ('Blue', 'Topwear')\nTrue labels:  ('Bags', 'Black')  Predicted labels:  ('Bags', 'Black')\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"While we did not classify the images into based on all the category classes, we were able to classify them into more than one labels at the same time. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}